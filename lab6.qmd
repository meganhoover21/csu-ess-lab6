---
title: "lab6"
author: "Megan Hoover"
format: html
---

#Load libraries for this lab
```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
library(ggthemes)
library(patchwork)
```
# Download data
```{r}
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
```

#download the documentation PDF which provides a descriptions for the various columns 
```{r}
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf')
```

# download the .txt files that store the actual data documented in the PDF. Create a vector storing the data types/file names we want to download:
```{r}
#data from the pdf that we want
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")
```

# Using glue, we can construct the needed URLs and file names for the data we want to download:
```{r}
# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
# where we want to download the data ...
local_files   <- glue('data/camels_{types}.txt')
```

# Now we can download the data: walk2 comes from the purrr package and is used to apply a function to multiple arguments in parallel (much like map2 works over paired lists). Here, we are asking walk2 to pass the first element of remote_files and the first element of local_files to the download.file function to download the data, and setting quiet = TRUE to suppress output. The process is then iterated for the second element of each vector, and so on.
```{r}
walk2(remote_files, local_files, download.file, quiet = TRUE)
```

# Once downloaded, the data can be read it into R using readr::read_delim(), again instead of applying this to each file individually, we can use map to apply the function to each element of the local_files list.
```{r}
# Read and merge data
camels <- map(local_files, read_delim, show_col_types = FALSE) 
```

# This gives us a list of data.frames, one for each file that we want to merge into a single table. So far in class we have focused on *_join functions to merge data based on a primary and foreign key relationship. In this current list, we have >2 tables, but, have a shared column called gauge_id that we can use to merge the data. However, since we have more then a left and right hand table, we need a more robust tool. We will use the powerjoin package to merge the data into a single data frame. powerjoin is a flexible package for joining lists of data.frames. It provides a wide range of join types, including inner, left, right, full, semi, anti, and cross joins making it a versatile tool for data manipulation and analysis, and one that should feel familiar to users of dplyr.

we are join to merge every data.frame in the list (n = 6) by the shared gauge_id column. Since we want to keep all data, we want a full join.
```{r}
camels <- power_full_join(camels ,by = 'gauge_id')
```

** Alternatively, we could have read straight from the urls. Strongly consider the implications of this approach as the longevity and persistence of the data is not guaranteed.

 Read and merge data:
camels <- map(remote_files, read_delim, show_col_types = FALSE) |> 
  power_full_join(by = 'gauge_id')
  
  

# Q1: From the documentation PDF, report what zero_q_freq represents
There's nothing in the pdf?

# Exploratory Data Analysis
## first, lets make a map of the sites. Use the borders() ggplot function to add state boundaries to the map and initially color the points by the mean flow (q_mean) at each site.
```{r}
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "pink", high = "dodgerblue") +
  ggthemes::theme_map()
```

** scales can be used to map data values to colors (scale_color_*) or fill aesthetics (scale_fill_*). There are two main types of color scales:

Discrete color scales – for things that are categories, like “apples,” “bananas,” and “cherries.” Each gets its own separate color.
scale_color_manual(values = c("red", "yellow", "pink")) #lets you pick your own colors.

Or

scale_color_brewer(palette = "Set1") #uses a built-in color set.

Continuous color scales – for numbers, like temperature (cold to hot) or height (short to tall). The color changes smoothly.
scale_color_gradient(low = "blue", high = "red") #makes small numbers blue and big numbers red.


# Q2: Make 2 maps of the sites, coloring the points by the aridty and p_mean column;
add clear labels, titles, and a color scale that makes sense for each parameter.
Ensure these render as a single image with your choice of facet_*, patchwork, or ggpubr
```{r}
#map of aridity
aridity_plot<-ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = aridity)) +
  scale_color_gradient(low = "blue", high = "red") +
  ggthemes::theme_map() +
  ggtitle("Map of Gauge Locations with Aridity Levels") +  # Title
  xlab("Longitude") +  # X-axis label
  ylab("Latitude")     # Y-axis label

#map of p_mean
p_meanplot<-ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "black") +
  geom_point(aes(color = p_mean)) +
  scale_color_gradient(low = "tan", high = "darkblue") +
  ggthemes::theme_map() +
  ggtitle("Map of Gauge Locations with Mean Precipitation Levels") +  # Title
  xlab("Longitude") +  # X-axis label
  ylab("Latitude")     # Y-axis label

# Combine the two maps into a single image using patchwork
aridity_plot | p_meanplot 
```


# Model Preparation
## As an initial analysis, lets look at the relationship between aridity, rainfall and mean flow. First, lets make sure there is not significant correlation between these variables. Here, we make sure to drop NAs and only view the 3 columns of interest.
```{r}
#given code to run
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```
As expected, there is a strong correlation between rainfall and mean flow, and an inverse correlation between aridity and rainfall. While both are high, we are going see if we can build a model to predict mean flow using aridity and rainfall.


# Visual EDA
## Lets start by looking that the 3 dimensions (variables) of this data. We’ll start with a XY plot of aridity and rainfall. We are going to use the scale_color_viridis_c() function to color the points by the q_mean column. This scale functions maps the color of the points to the values in the q_mean column along the viridis continuous (c) palette. Because a scale_color_* function is applied, it maps to the known color aesthetic in the plot.
